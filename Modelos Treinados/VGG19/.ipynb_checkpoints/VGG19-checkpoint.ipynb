{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IF0_Kgij7PBz"
   },
   "source": [
    "# VGG19 para previsão de IDC em imagens histológicas:\n",
    "## Autor: Otávio A M Guerra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKFm6o9h5X5x"
   },
   "source": [
    "## Import das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "6CYCz0MmVz4Q",
    "outputId": "723d9949-a39c-427a-fc8c-e856bf00b961"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "Wait for 8 seconds...\n",
      "TensorBoard link:\n",
      "https://a6ee28a0.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U tensorboardcolab\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorboardcolab import *\n",
    "from keras.utils import Sequence\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "tbc=TensorBoardColab()\n",
    "\n",
    "# Import das bibliotecas de construcao da rede neural\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dQWNzcM55rWw"
   },
   "source": [
    "## Definindo função que lerá as imagens dos arquivos csv em batches para entrado na rede:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTTQWx3CV82T"
   },
   "outputs": [],
   "source": [
    "def csv_image_generator(inputPath, bs, mode=\"train\", aug=None):\n",
    "\t# Abre o arquivo csv para leitura\n",
    "\tf = open(inputPath, \"r\")\n",
    "\n",
    "\t# Loop infinito\n",
    "\twhile True:\n",
    "\t\t# Inicializa vetores de imagens e classes\n",
    "\t\timages = []\n",
    "\t\tlabels = []\n",
    "\n",
    "\t\t# Loop ate atingir o BatchSize\n",
    "\t\twhile len(images) < bs:\n",
    "\t\t\t# Lê a proxima linha do CSV\n",
    "\t\t\tline = f.readline()\n",
    "\n",
    "\t\t\t# Se a linha tiver vazia isso indica que chegamos ao\n",
    "\t\t\t# fim do arquivo\n",
    "\t\t\tif line == \"\":\n",
    "\t\t\t\t# Reseta o ponteiro do arquivo para o inicio\n",
    "\t\t\t\t# e lê novamente a primeira linha\n",
    "\t\t\t\tf.seek(0)\n",
    "\t\t\t\tline = f.readline()\n",
    "\n",
    "\t\t\t\t# Se estamos avaliando entao temos que sair do loop\n",
    "\t\t\t\t# para garantirmos que nao avaliaremos o modelo 2 vezes\n",
    "                # em amostras do inicio do arquivo\n",
    "\t\t\t\tif mode == \"eval\":\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t# Extrai a classe da imagem e constroi a mesma\n",
    "\t\t\tline = line.strip().split(\",\")\n",
    "\t\t\tlabel = int(line[0])\n",
    "\t\t\timage = np.array([int(x) for x in line[1:]], dtype=\"uint8\")\n",
    "\t\t\timage = image.reshape((50, 50, 3))\n",
    "\n",
    "\t\t\t# Atualiza as listas do Batch\n",
    "\t\t\timages.append(image)\n",
    "\t\t\tlabels.append(label)\n",
    "\n",
    "\t\t# Trata parametro de Data Augmentation\n",
    "\t\tif aug is not None:\n",
    "\t\t\t(images, labels) = next(aug.flow(np.array(images),\n",
    "\t\t\t\tlabels, batch_size=bs))\n",
    "\n",
    "\t\t# yield the batch to the calling function\n",
    "\t\tyield (np.array(images), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CtS8Dnot6EAz"
   },
   "source": [
    "## Definindo variaveis e caminhos dos arquivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIlxWYLR2dV2"
   },
   "outputs": [],
   "source": [
    "# Path dos CSV's\n",
    "TRAIN_CSV = \"/content/drive/My Drive/TCC/Projeto/dataset/IDC_training.csv\"\n",
    "TEST_CSV = \"/content/drive/My Drive/TCC/Projeto/dataset/IDC_test.csv\"\n",
    "VAL_CSV = \"/content/drive/My Drive/TCC/Projeto/dataset/IDC_validation.csv\"\n",
    "\n",
    "# Numero de Epocas e Batch Size\n",
    "NUM_EPOCHS = 10\n",
    "BS = 128\n",
    "\n",
    "# initialize the total number of training and testing image\n",
    "NUM_TRAIN_IMAGES = 0\n",
    "NUM_TEST_IMAGES = 0\n",
    "NUM_VAL_IMAGES = 0\n",
    "\n",
    "# open the training CSV file, then initialize the unique set of class\n",
    "# labels in the dataset along with the testing labels\n",
    "f = open(TRAIN_CSV, \"r\")\n",
    "labels = set()\n",
    "testLabels = []\n",
    "\n",
    "# loop over all rows of the CSV file\n",
    "for line in f:\n",
    "\t# extract the class label, update the labels list, and increment\n",
    "\t# the total number of training images\n",
    "\tlabel = line.strip().split(\",\")[0]\n",
    "\tlabels.add(label)\n",
    "\tNUM_TRAIN_IMAGES += 1\n",
    "\n",
    "# close the training CSV file and open the testing CSV file\n",
    "f.close()\n",
    "f = open(TEST_CSV, \"r\")\n",
    "\n",
    "# loop over the lines in the testing file\n",
    "for line in f:\n",
    "\t# extract the class label, update the test labels list, and\n",
    "\t# increment the total number of testing images\n",
    "\tlabel = int(line.strip().split(\",\")[0])\n",
    "\ttestLabels.append(label)\n",
    "\tNUM_TEST_IMAGES += 1\n",
    "\n",
    "# close the testing CSV file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POHlcuX66c-r"
   },
   "source": [
    "## Construindo o \"gerador\" de imagens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WLYPQIAD2iAO"
   },
   "outputs": [],
   "source": [
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize both the training and testing image generators\n",
    "trainGen = csv_image_generator(TRAIN_CSV, BS, mode=\"train\", aug=aug)\n",
    "testGen = csv_image_generator(TEST_CSV, BS, mode=\"train\", aug=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-pVkaz1H6iPK"
   },
   "source": [
    "## Importação e definição do modelo VGG19:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xHjz6Z8O2mM5",
    "outputId": "0ed97d29-ee9e-4807-c667-f6dab86c76a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "W0727 18:25:15.124035 140621304436608 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0727 18:25:15.136137 140621304436608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 50, 50, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 50, 50, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 20,550,721\n",
      "Trainable params: 20,438,145\n",
      "Non-trainable params: 112,576\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "img_width, img_height = 50, 50\n",
    "\n",
    "\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "# Freeze the layers which you don't want to train.\n",
    "# Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "print(model_final.summary())\n",
    "\n",
    "# Salva o .summary() do modelo em um arquivo texto\n",
    "with open('VGG19summary.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model_final.summary()\n",
    "\n",
    "model_final.compile(loss = \"binary_crossentropy\", optimizer = optimizers.Adam(lr=0.0001), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REr9dtc4nYDu"
   },
   "source": [
    "## Definindo callbacks para salvar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7hFh_SaUnXLS"
   },
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg19_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASOhMvSZ6wW2"
   },
   "source": [
    "## Treinando o modelo e realizando predições no conjunto de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767
    },
    "colab_type": "code",
    "id": "a3NleXgt2-8V",
    "outputId": "e4ac5ec0-5d47-46b0-fcc5-3a9dc919e51c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Iniciando treinamento...\n",
      "\n",
      "Epoch 1/10\n",
      "2011/2011 [==============================] - 859s 427ms/step - loss: 0.3383 - acc: 0.8560 - val_loss: 0.3816 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83694, saving model to vgg19_1.h5\n",
      "Epoch 2/10\n",
      "2011/2011 [==============================] - 842s 419ms/step - loss: 0.2939 - acc: 0.8760 - val_loss: 0.3899 - val_acc: 0.8356\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.83694\n",
      "Epoch 3/10\n",
      "2011/2011 [==============================] - 839s 417ms/step - loss: 0.2817 - acc: 0.8814 - val_loss: 0.3873 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.83694\n",
      "Epoch 4/10\n",
      "2011/2011 [==============================] - 834s 415ms/step - loss: 0.2715 - acc: 0.8861 - val_loss: 0.3530 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.83694 to 0.85176, saving model to vgg19_1.h5\n",
      "Epoch 5/10\n",
      "2011/2011 [==============================] - 826s 411ms/step - loss: 0.2654 - acc: 0.8891 - val_loss: 0.3315 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.85176 to 0.86328, saving model to vgg19_1.h5\n",
      "Epoch 6/10\n",
      "2011/2011 [==============================] - 834s 415ms/step - loss: 0.2590 - acc: 0.8924 - val_loss: 0.3128 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.86328 to 0.86759, saving model to vgg19_1.h5\n",
      "Epoch 7/10\n",
      "2011/2011 [==============================] - 827s 411ms/step - loss: 0.2548 - acc: 0.8938 - val_loss: 0.3131 - val_acc: 0.8645\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.86759\n",
      "Epoch 8/10\n",
      "2011/2011 [==============================] - 831s 413ms/step - loss: 0.2507 - acc: 0.8962 - val_loss: 0.3035 - val_acc: 0.8736\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.86759 to 0.87360, saving model to vgg19_1.h5\n",
      "Epoch 9/10\n",
      "2011/2011 [==============================] - 835s 415ms/step - loss: 0.2489 - acc: 0.8973 - val_loss: 0.2958 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.87360 to 0.87420, saving model to vgg19_1.h5\n",
      "Epoch 10/10\n",
      "2011/2011 [==============================] - 832s 414ms/step - loss: 0.2431 - acc: 0.8993 - val_loss: 0.2936 - val_acc: 0.8777\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.87420 to 0.87770, saving model to vgg19_1.h5\n"
     ]
    }
   ],
   "source": [
    "print(\"[START] Iniciando treinamento...\\n\")\n",
    "H = model_final.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=NUM_TRAIN_IMAGES // BS,\n",
    "\tvalidation_data=testGen,\n",
    "\tvalidation_steps=NUM_TEST_IMAGES // BS,\n",
    "\tepochs=NUM_EPOCHS,\n",
    "    callbacks = [checkpoint, early])\n",
    "\n",
    "# re-initialize our testing data generator, this time for evaluating\n",
    "testGen = csv_image_generator(TEST_CSV, BS,\n",
    "\tmode=\"eval\", aug=None)\n",
    "\n",
    "# make predictions on the testing images, finding the index of the\n",
    "# label with the corresponding largest predicted probability\n",
    "predIdxs = model_final.predict_generator(testGen,\n",
    "\tsteps=(NUM_TEST_IMAGES // BS) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJmxlEjdxj2S"
   },
   "source": [
    "## Plot da curva de aprendizado e Classification Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCFWkRgINCbc"
   },
   "outputs": [],
   "source": [
    "def get_label(proba):\n",
    "    if proba >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "predLabels = [get_label(i) for i in list(predIdxs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "2z9DnBhn3BJN",
    "outputId": "273fc697-cf82-4faf-9dff-529885392db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Métricas] Avaliando a rede no conjunto de Teste...\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      5000\n",
      "           1       0.89      0.86      0.88      5000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show a nicely formatted classification report\n",
    "print(\"[Métricas] Avaliando a rede no conjunto de Teste...\\n\")\n",
    "print(classification_report(testLabels,predLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "dXlIUa68SVcZ",
    "outputId": "e1d434ed-afc4-4c78-9c3e-e96c335aebe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia Balanceada: 0.8778999999999999\n",
      "ROC-AUC: 0.8778999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "print(\"Acuracia Balanceada: {}\".format(balanced_accuracy_score(testLabels,predLabels)))\n",
    "print(\"ROC-AUC: {}\".format(roc_auc_score(testLabels,predLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9Ph6CNcPT8H"
   },
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = 10\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"test_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"test_acc\")\n",
    "plt.title(\"Loss e Acurácia no Conjunto de Treino e Teste\")\n",
    "plt.xlabel(\"Epoca #\")\n",
    "plt.ylabel(\"Loss/Acurácia\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "VGG19.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
